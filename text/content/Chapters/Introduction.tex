% Chapter 1

\chapter{Introduction}

\label{ch:introduction}

Argumentation is a fundamental aspect of human communication, surfacing in
contexts that range from informal discussions to legal reasoning. Beyond
persuasion, argumentative exchanges support critical thinking, collective
decision-making, and the construction of shared knowledge. Understanding how
arguments are structured, how they interact, and how they can be evaluated is
therefore a central challenge for both the social sciences and Artificial
Intelligence (AI).

Recent advances in argumentation mining attempt to automatically detect the
building blocks of argumentative discourse (claims, premises, supports, and
attacks) directly from text \citep{stab2017parsing}. The quality of these
pipelines depends on coordinating several interdependent subtasks: deciding
whether a span of text is argumentative, classifying its role, and predicting
how it relates to the rest of the discourse. Errors in the early stages easily
propagate to later ones, eroding the coherence of the recovered argumentative
graph. Neuro-symbolic methods are especially attractive in this setting because
they combine neural networks, which excel at processing unstructured language,
with symbolic reasoning, which enforces global consistency and domain
constraints.

The foundational joint model of \citet{stab2017parsing} couples local
classifiers with Integer Linear Programming (ILP) constraints that capture the
shape of well-formed argumentative structures. ILP-based approaches improved
consistency over pipeline baselines, yet they struggle to represent uncertainty
and incur a combinatorial cost when the search space grows. Probabilistic Logic
Programming (PLP) systems, such as ProbLog \citep{fierens2015}, mitigate these
limitations by natively handling stochastic information while retaining the
declarative and explainable nature of logic programs. Frameworks like
DeepProbLog \citep{manhaeve2018deepproblog} and its application to argumentation
mining \citep{cerveira2023argumentation} demonstrate how neural predictions can
be wired into symbolic models that reason about argumentative structure.

Extending this line of work, \textsc{smProbLog} adopts the stable model
semantics of Answer Set Programming (ASP), unlocking the ability to represent
negative cycles and other non-monotonic phenomena that occur in real-world
argumentation \citep{totis2023smproblog}. Stable models are expressive enough
to encode the bipolar argumentation frameworks we study in this thesis, but
their probabilistic extensions quickly lead to intractable inference when
treated na√Øvely.

This dissertation examines how probabilistic ASP (PASP) can be compiled into
structured probabilistic circuits that support tractable inference and learning.
By embedding argumentative constraints into compiled circuits we seek to align
neural predictions with the semantics of bipolar argumentation, enabling
transparent reasoning, calibrated uncertainty, and scalable training loops. The
central questions we explore are:
\begin{itemize}
  \item How can argumentation mining tasks be encoded as PASP programs that
  capture the mutual influence of claims, premises, supports, and attacks while
  preserving probabilistic semantics for uncertain or conflicting evidence?
  \item Which knowledge compilation strategies can translate these PASP
  encodings into circuits that admit efficient marginal and conditional
  inference?
  \item How can the resulting circuits interface with neuro-symbolic learning,
  allowing gradients or other learning signals to flow through compiled
  structure without sacrificing explainability?
\end{itemize}

The remainder of this document is organized as follows. Chapters
\autoref{ch:sat}, \autoref{ch:amc}, and \autoref{ch:asp} review background on
propositional satisfiability, algebraic model counting, and logic programming
with stable models. Chapter \autoref{ch:contribution} then introduces our PASP
encoding of bipolar argumentation, the knowledge compilation pipeline that
supports it, and the circuit properties required for efficient inference. We
later position our approach with respect to the literature and discuss the
experimental questions that guide our evaluation.

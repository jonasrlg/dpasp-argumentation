% Appendix Answer Set Programming

\chapter{Answer Set Programming}
\label{ch:asp}

Knowledge Representation (KR) research is driven by a familiar tension:
expressive formalisms capture rich domains but typically incur intractable
inference, while restricted languages admit efficient reasoning at the cost of
what can be expressed. Full first-order logic, for example, allows us to encode
complex knowledge bases but entailment in this setting is undecidable in
general and, even for decidable fragments, often demands exponential resources
\citep{levesque1986knowledge}. Despite numerous refinements, classical
resolution-based procedures inherit this worst-case behaviour.

One way to regain tractability is to move to less expressive yet carefully
designed fragments. Propositional logic exemplifies this strategy: by grounding
away quantifiers we can apply SAT technology, as discussed in
Chapter~\ref{ch:sat}. Answer Set Programming (ASP) follows the same philosophy.
It restricts syntax in a way that keeps many modelling conveniences—default
negation, recursion, and non-monotonic reasoning—while providing a semantics
that supports efficient solver implementations. ASP has become a workhorse for
applications ranging from planning to computational argumentation
\citep{toni2011argumentation}.

This chapter reviews the logical foundations required for the probabilistic ASP
encodings that we adopt later. We begin with definite programs and the
associated semantic machinery, introduce stable-model semantics through loop
formulas and related constructs, and then extend the language with features
such as disjunction and cardinality constraints. These ingredients will be
essential when we encode bipolar argumentation in Chapter~\ref{ch:contribution}.
%----------------------------------------------------------------------------------------
\section{Foundations of Logic Programming} \label{sec:lp}

\subsection{Definite Logic Programs}

Before diving on the semantics of Probabilistic Answer Set Programming (PASP), it is important to
understand less expressive formalisms, such as \textit{definite}
and \textit{propositional} programs. These formalisms are not only
the basis where Answer Set Programming (ASP) is built upon, but also hint at the
underlying complexity of the problems that Answer Set Programming (ASP) can solve
and the efficiency of the algorithms that can be used in this
context. Thus, we start by defining the simplest form of
Logic Programming (LP), called \textit{definite} (or \textit{positive})
programs:

\begin{definition}[Definite Logic Programs]
    A definite logic program $P$ is a finite set of clauses
    (rules) in the form
    \begin{minted}{prolog}
        a :- b1, ..., bM.
    \end{minted}
    where $a, b_1, \ldots, b_M$ are atoms of a function-free
    FOL $L$; and this rule can be seen as material
    implication restricted to Horn clauses, where
    \mintinline{prolog}{a :- b1, ..., bM} is read as $B \supset
    A$ or $B \rightarrow A$ \citep{eiter2009answer}. The atom
    $a$ is called the \textit{head} of the rule, while $b_1,
    \ldots , b_m$ are called the rule’s \textit{body}. When a
    rule has an empty body, it is called a fact and can be
    shortened as $a$.

    The following program is an example of a definite program:
    \begin{minted}{prolog}
        happy(turing) :- friends(turing, vonNeumann).
    \end{minted}

    Programs without variables, like the one above, are called
    \textit{propositional} programs.
\end{definition}

We could skip the definition of propositional programs, if we
were not interested in the complexity of this problem, that is
not only $P-complete$, but can be solved in linear time
(testing satisfiability of propositional (Horn) formulas)
\citep{dowling1984linear}.

\subsection{Herbrand Universe, Base and Interpretation}

A natural question that arises after the definition of this new
class of program is about its complexity. This answer largely
depends on the type of normal program that we are dealing with.
In search of a more formal explanation, we have to introduce
more concepts to capture a class of programs that we are
comfortable between the trade-off of expressiveness and
efficiency. We do this by firstly defining the concept of
\textit{Herbrand Universe} and \textit{Base}:

\begin{definition}[Herbrand Universe]
    The \textit{Herbrand Universe} $HU(P)$ of a logic program $P$
    is the set of all terms that can be formed from constants
    and functions in $P$ (w.r.t. a predefined vocabulary $L$).
    Moreover, the \textit{Herbrand Base} $HB(P)$ of $P$ is the set
    of all ground atoms that can be formed from terms and
    predicates occurring $HU(P)$. Finally, the \textit{Herbrand
    Interpretation} is a subset of $HB(P)$, an interpretation
    $I$ (a set denoting ground \textit{truths}) over $HU(P)$.
\end{definition}

\begin{example}
    Consider the following logic program $P$
    \citep{eiter2009answer}:
    \begin{minted}{prolog}
        h(0, 0).
        t(a, b, r).
        p(0, 0, b).
        p(f(X), Y, Z) :- p(X, Y, Z'), h(X, Y), t(Z, Z', r).
        h(f(X), f(Y)) :- p(X, Y, Z'), h(X, Y), t(Z, Z', r).
    \end{minted}
    Then, the Herbrand Universe $HU(P)$ is the union of the set
    containing all constants of $P$, $\{0, a, b, r\}$, and the
    set of terms that can be formed from these constants
    $\{f(0), f(a), f(b), f(r), f(f(0)), f(f(a)), f(f(b)),
    f(f(r)), \ldots\}$. Whereas, the Herbrand Base, $HB(P)$ is
    given by the set of all ground atoms assertions, $\{p(0, 0,
    0), p(a, a, a), \ldots, h(0, 0), \ldots, t(0, 0, 0), t(a, a,
    a), \ldots\}$.

    Finally, we list a few Herbrand Interpretations over
    $HU(P)$:

    \begin{itemize}
        \item $I_1 = \emptyset$;
        \item $I_2 = HB(P)$;
        \item $I_3 = \{h(0, 0), t(a, b, r), p(0, 0, b)\}$.
    \end{itemize}
    Note that not all interpretations are consistent with the
    program $P$. For instance, $I_1$ is contradictory because it
    does not include any of the facts of $P$.
\end{example}

\subsection{Grounding of a Logic Program}

With the notion of Herbrand Universe and Base, we can now have
a moral formal definition of \textit{grounding}
\citep{eiter2009answer}:

\begin{definition}[Grounding]
    We define a ground instance of a clause $C$, of a logic
    program  $P$, as any clause $C'$ obtained from $C$ by
    applying a substitution
    \begin{displaymath}
        \theta: Var(C) \rightarrow HU(P),
    \end{displaymath}
    where $Var(C) \in \mathcal{V}(P)$ is the set of variables
    in $C$. Moreover, the grounding of a program $P$ is the set
    of all possible ground instances of the clauses in $P$ and
    is denoted by $ground(P) = \bigcup_{C \in P} ground(C)$ (the
    union of all ground instances for all the clauses in $P$).
\end{definition}

\subsection{Interpretation of a Logic Program}

As we are already formalizing the concepts like grounding, the
Interpretation of a logic program is also a concept that needs
more attention. Thus, follows its definition:

\begin{definition}[Interpretation]
    The interpretation $I$ of a logic program $P$ is a model of
    $P$ that is compatible with the assertions in $P$. That is,
    $I$ is a model of

   \begin{itemize}
        \item A ground clause $C =$ \mintinline{prolog}{a :- b1, ..., bM, not c1, ..., cN},
        denoted $I \models C$, if either $\Set{a, c_1, \ldots,
        c_N} \cap I \ne \emptyset$ or $\Set{b_1, \ldots, b_M}
        \not \subseteq I$;
        \item A clause $C$, denoted $I \models C$, if $I \models
        C'$ for every $C' \in ground(C)$;
        \item A program $P$, denoted $I \models P$, if
        $I \models C$ for every clause $C \in P$.
   \end{itemize}
   That is: an interpretation $I$ is a model of a program $P$ if
   it is compatible with all the ground instances of the clauses
   of $P$.

   We call a model $I$ of a program $P$ a \textit{minimal model},
   if there is no other model $J$ of $P$ such that $J \subset
   I$. Although, Normal logic programs can have multiple minimal models
   for a program, it is true that Definite Logic Programs only
   have one minimal model \citep{eiter2009answer}.
\end{definition}

\subsection{Loop Formulas}

\begin{definition}[Loops]
    Let $P$ be a normal logic program. Any nonempty subset $L$
    of the atoms of $P$ is called a \textit{loop} if for any two
    atoms $p,q$ in $L$, there is a path in the dependency graph
    of $P$ from $p$ to $q$ of length greater than zero.

    We also associate two sets of rules with a loop $L$:
    \begin{itemize}
        \item The set of rules $R^+(L,P)$ contains rules of $P$
        whose heads and bodies are in $L$; and
        \item The set of rules $R_L^-(L,P)$ contains rules about
        atoms in $L$ that are out of the loop $L$.
    \end{itemize}
\end{definition}

\begin{definition}[Loop Formulas]
    Let $P$ be a normal logic program and $L$ be a loop of $P$.
    Then, the \textit{loop formula} $LF(L,P)$ is the following
    implication:
    \begin{displaymath}
        \bigvee_{p \in L} \neg p \;\rightarrow\; \neg \bigwedge_{r
        \in R_L^{-}(L,P)} \mathrm{body}(r),
    \end{displaymath}
    where $\mathrm{body}(r)$ is the body of the rule $r$.
\end{definition}

The main idea behind loop formulas is that they can be used to
transform logic programs under stable model semantics to
propositional theories. This is particularly useful when these
propositional theories are fed into SAT solvers to compute
stable models. The entire process of translating a logic program
by this approach includes: using Clark's completion to create a
propositional theory and augment it by using additional loop
formulas, that guarantees that this theory admits only stable
models \citep{lin2004assat}. One problem with this approach is
that the number of loop formulas must be controlled in some
way, because there can be an exponential number of loop formulas
for a given program \citep{eiter2009answer}.

\section{Answer Set Programming} \label{sec:asp}

Finally, after defining the main semantics for logic programs
that include negation, we introduce the concept of ASP,
an extension of normal logic programming that allows for the use
of: integrity constraints, strong negation, disjunctive rules,
and choice rules \citep{eiter2009answer, maua2020complexity}.

\subsection{Extended Logic Programs}

We start this ASP definition by first introducing the
concept of Extended Logic Programs (ELP) and Extended Disjunctive
Logic Programs (EDLP), programs that use the three
extensions defined above.

\subsubsection{Integrity Constraints}

Integrity constraints rule out interpretations that violate hard requirements.
They are typically written as headless rules of the form

\begin{minted}{prolog}
    :- b1, ..., bM, not c1, ..., not cN.
\end{minted}

The same requirement can be expressed with a head by introducing an auxiliary
predicate:

\begin{minted}{prolog}
    falsity :- b1, ..., bM, not falsity, not c1, ..., not cN,
\end{minted}

where the auxiliary $falsity$ is a fresh propositional atom
\citep{eiter2009answer}.

\subsubsection{Strong Negation}

Strong negation is not strictly required—default negation combined with
integrity constraints can simulate it—but having a dedicated connective makes
programs clearer. While classical logic writes the fact that $a$ is known to be
false as $\neg a$, ASP customarily denotes it by $-a$.

\subsubsection{Extended Logic Programs}

By combining normal logic programs with integrity constraints
and strong negation, we are capable of defining ELP:

\begin{definition}[Extended Logic Programs]
    An extended logic program $P$ is a finite set of rules of
    the form:
    \begin{minted}{prolog}
        a :- b1, ..., bM, not c1, ..., not cN,
    \end{minted}
    where $M, N \geq 0$; $a, b_i, c_i$ are atoms or
    \textit{strongly negated} atoms of a FOL.
\end{definition}

Because integrity constraints and strong negation can be reduced to the basic
semantics, we do not need a new notion of model: stable models of extended
programs remain \emph{answer sets}.

\subsubsection{Disjunctive Logic Programs}

The last extension that we define for normal logic programs is:
the addition of disjunctions on the head of rules:
\begin{definition}[Extended Disjunctive Logic Programs]
    An extended disjunctive logic program $P$ is a finite set
    of rules of the form:
    \begin{minted}{prolog}
        a1 ; ... ; aK :- b1, ..., bM, not c1, ..., not cN,
    \end{minted}
    where $K, M, N \geq 0$; $a_i, b_i, c_i$ are atoms or
    \textit{strongly negated} atoms of a FOL; and the
    symbol $;$ denotes disjunction (similar to how commas
    denote conjunctions).
\end{definition}

The semantics of EDLPs mirror those of extended programs with two additions:
answer sets are now minimal models of the reduct $P^M$ (which may have multiple
minimal models), and Clark's completion must be generalised to cope with
disjunctive heads \citep{alviano2016completion}.

Finally, we recall the notion of interpretation for EDLPs, unifying the various
extensions that lead from normal logic programs to full ASP.

\begin{definition}[Interpretation (of an EDLP)]
    Let $P$ be an EDLP. An interpretation $I$ is a model
    of:
    \begin{enumerate}
        \item A ground clause $C =$ \mintinline{prolog}{a1; ...; aK :- b1, ..., bM, not c1, ..., cN},
        denoted $I \models C$, if either $\Set{a_1, \ldots, a_K,
        c_1, \ldots, c_N} \cap I \ne \emptyset$ or $\Set{b_1,
        \ldots b_M} \not \subseteq I$;
        \item A clause $C$, denoted $I \models C$, if $I \models
        C$ for every $C' \in ground(C)$; and
        \item A program $P$, denoted $I \models P$, if $I
        \models C$ for every clause $C \in P$.
    \end{enumerate}
\end{definition}

\subsection{Cardinality Constraints}

The last extension that characterises Answer Set Programming is the notion of
\textit{cardinality constraints}, constructs of the
form: \mintinline{prolog}{L \{l1, ..., ln \} U}, that are
satisfied whenever the number of satisfied literals $l_i$ is
between the integral bounds $L$ and $U$, inclusive
\citep{syrjanen2001smodels}. As Syrjänen and Niemelä described,
a cardinality constraint in a rule head imposes a
non-deterministic choice over the literals in it when the rule
body is satisfied.

\subsubsection{Choice Rules}

A special case of cardinality constraints are \textit{choice
rules}: rules where the head is enclosed in brackets and
represent the idea that the head can be included in a stable
model only if the body holds; but it can be left out, too
\citep{syrjanen2001smodels}. This type of rule can be expressed
through normal rules by introducing a new atom. For example,

\begin{example}
    The following program $P$
    \begin{minted}{prolog}
        {a} :- b, not c.
    \end{minted}
    is equivalent to the Normal logic program $P'$:
    \begin{minted}{prolog}
        a :- not aa, b, not c.
        aa :- not a.
    \end{minted}
\end{example}

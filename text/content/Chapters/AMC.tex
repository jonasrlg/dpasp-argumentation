% Appendix Algebraic Model Counting

\chapter{Probabilistic Logical Inference} % Chapter title

\label{ch:amc} % For referencing the chapter elsewhere, use \autoref{ch:examples}
%----------------------------------------------------------------------------------------

Chapter \autoref{ch:sat} introduced SAT and its counting and optimisation
variants. Weighted model counting (WMC) is especially important for us because
it reduces many probabilistic inference tasks to summing weights over satisfying
assignments \citep{darwiche2002logical,chavira2008probabilistic}. By encoding,
for example, a Bayesian network as a propositional theory whose literals carry
probabilities, WMC answers marginal queries through purely logical machinery.

Knowledge compilation builds on this reduction: once a theory has been compiled
into a circuit that supports fast WMC, evidence and query evaluation become
linear in the circuit size \citep{chavira2006compiling,kimmig2017algebraic}. To
reason about PASP we need a framework that encompasses classical SAT, WMC, and
other algebraic tasks. Algebraic Model Counting (AMC) provides precisely that
unifying perspective \citep{kimmig2017algebraic}. A recent extension, second
level AMC (2AMC), further captures probabilistic ASP inference
\citep{kiesel2022efficient}. This chapter introduces these abstractions and
prepares the ground for the compilation pipeline described later.

%------------------------------------------------

\section{From SAT to AMC}

Before defining AMC we recall the algebraic structure that underpins it.
Generalising from simple numeric addition and multiplication allows us to model
counting, optimisation, and probability computations within the same template.

\section{Semirings}

\begin{definition}[Semiring]
    A semiring is an algebraic structure $(\mathcal{A}, \oplus,
    \otimes, e_{\oplus}, e_{\otimes})$ where addition $\oplus$
    and multiplication $\otimes$ are associative binary
    operations on $\mathcal{A}$, $\oplus$ is commutative,
    $\otimes$ distributes over $\oplus$, $e_{\oplus}$ and
    $e_{\otimes}$ are neutral elements for $\oplus$ and $\otimes$,
    respectively, and $e_{\oplus}$ annihilates multiplication:
    $e_{\oplus} \otimes a = a \otimes e_{\oplus} = e_{\oplus}$
    for every $a \in \mathcal{A}$. In a \emph{commutative}
    semiring, multiplication $\otimes$ is also commutative.
\end{definition}

Semirings appear throughout computer science. The \emph{tropical} semiring, for
instance, replaces addition with the minimum operator and multiplication with
the standard addition over extended real numbers
\citep{simon1988recognizable}. When used with AMC it captures optimisation tasks
like Max-SAT: summations aggregate clause scores while products accumulate costs
along a derivation.

\section{Algebraic Model Counting}

\begin{definition}[Algebraic Model Counting]
    Given
    \begin{itemize}
        \item A propositional logic theory $T$ over a set of
        variables $\mathcal{V}$;
        \item A commutative semiring $(\mathcal{A}, \oplus,
        \otimes, e_{\oplus}, e_{\otimes})$; and
        \item A labelling function $\alpha: \mathcal{L}
        \rightarrow \mathcal{A}$, mapping literals $\mathcal{L}$
        of the variables in $\mathcal{V}$ to elements of the
        semiring set $\mathcal{A}$.
    \end{itemize}
    The AMC problem is now defined as the computation of
    the following expression:
    \begin{displaymath}
        A(T) = \bigoplus_{I \in \mathcal{M}(T)} \bigotimes_{i
        \in I} \alpha(i),
    \end{displaymath}
    where $\mathcal{M}(T)$ denotes the set of models of $T$.
\end{definition}

To anyone familiar with introductory algebra, it is easy to see
that the definition above for the AMC problem indeed
reduces many of the presented SAT like problems. For
example, by setting the semiring to
$$ (\mathcal{A}, \oplus, \otimes, e_{\oplus}, e_{\otimes}) =
(\{\mathit{true}, \mathit{false}\}, \lor, \land, \mathit{false},
\mathit{true}),$$

and $\alpha$ maps positive literals to \textit{true} and negative
literals to \textit{false}, we can see that the AMC problem
is capable of solving the SAT problem. Moreover, by setting
a similar semiring

$$ (\mathcal{A}, \oplus, \otimes, e_{\oplus}, e_{\otimes}) =
(\mathbb{N}, +, \times, 0, 1),$$

and $\alpha$ to map literals to $1$ and $0$, if they
are positive or negative, respectively, we can see that the
AMC models model counting.

Similarly, by only changing the set $\mathcal{A}$ of the
semiring to $\mathbb{R}^+$ (non-negative real numbers) and
$\alpha$ to also map literals to $\mathbb{R}^+$, we can see that
the AMC problem is capable of solving the WMC problem.

Moreover, by the results cited previously about Bayesian Networks, one can see
that this also means that AMC is also capable of reducing
general probabilistic inference \citep{darwiche2002logical,chavira2006compiling,
chavira2008probabilistic,sang2005performing}. However, the
algebraic structure of AMC makes it easy to show that it is
capable of modeling probabilistic inference: by using the same semiring used to
model the WMC problem and just by changing the $\alpha$
function to represent a probability distribution over the
literals, setting $a(v) \in [0,1]$ and $a(\overline{v})$ to be
its complement.

\begin{example}
    Consider the theory $T = (a \lor b)$ and the probability
    semiring $\big(\mathbb{R}_{\geq 0}, +, \times, 0, 1\big)$.
    Let the labelling function assign weights
    $\alpha(a)=0.6$, $\alpha(\neg a)=0.4$, $\alpha(b)=0.3$, and
    $\alpha(\neg b)=0.7$. The models that satisfy $T$ are all
    assignments except $(\neg a, \neg b)$. Applying the AMC
    formula yields
    \[
        A(T) = 1 - \alpha(\neg a)\alpha(\neg b)
             = 1 - 0.4 \times 0.7 = 1 - 0.28 = 0.72,
    \]
    which coincides with the probability that at least one of
    $a$ or $b$ is true. This simple computation mirrors the WMC
    task we will perform on compiled circuits.
\end{example}

In fact, AMC is capable of modeling many other interesting
problems, such as $EXPEC$ (expectation), which allows one to
infer parameters in a Finite State Transducer model w.r.t. to a given dataset.
Hence, the elements of the respective expectation semiring are
tuples of the form $(p, v)$, where $p \in [0,1]$ is a
probability of an arc of the Finite State Transducer and $v \in \mathbb{R}$ is
the value of this respective arc. Then, the operations $\oplus,
\otimes$, neutral elements $e_{\oplus}, e_{\otimes}$, and the
labelling function $\alpha$ are defined as follows:

\begin{align*}
    (p_1, v_1) \oplus (p_2, v_2) & = (p_1 + p_2, v_1 + v_2), \\
    (p_1, v_1) \otimes (p_2, v_2) & = (p_1 \cdot p_2, p_1 \cdot
    v_2 + p_2 \cdot v_1), \\
    e_{\oplus} & = (0, 0), \\
    e_{\otimes} & = (1, 0), \\
    \alpha(a) & =
    \begin{cases}
        (p, 1) & \text{if } i = k, \\
        (p, 0) & \text{else.}
    \end{cases},
\end{align*}

where $a$ is the respective arc of the Finite State Transducer, in relation to
the tuple $(p, v)$.

%Furthermore, the AMC problem also is capable of reducing
%Max-SAT to it, by setting the semiring $(\mathbb{R}^+,
%\max, +, 0, 0)$, and the labeling function $\alpha(l)$, which
%maps literals to their respective weight contribution for all
%clause $c$ that the literal appears in. More specifically, the
%labeling function $\alpha$ is defined as follows:
%
%$$\alpha(l) = \sum_{c \in C : l \in c} \frac{w(c)}{|c|},$$
%
%where $C$ is the respective set of clauses of the propositional
%logic theory $T$, $w(c)$ is the weight of the clause $c$, and
%$|c|$ is the number of literals in the clause $c$.

Adapted from \citep{kimmig2017algebraic}, Table \ref{tab:amc}
summarises AMC instances for different logical and probabilistic
tasks, detailing the underlying sets, operations, and labelling
functions for each semiring.

\begin{table}
    \begin{center}
        \begin{tabular}{|c||c|c|c|c|c|c|c|}
            \hline
            $\mathrm{Task}$ & $\mathcal{A}$ & $\oplus$ & $\otimes$ &
            $e^{\oplus}$ & $e^{\otimes}$ & $\alpha(v)$ &
            $\alpha(\neg v)$ \\ \hline \hline
            $\mathrm{SAT}$ & $\set{\mathit{true},\mathit{false}}$ &
            $\vee$ & $\wedge$ & $\mathit{false}$ & $\mathit{true}$ &
            $\mathit{true}$ & $\mathit{true}$ \\ \hline
            $\mathrm{\#SAT}$ & $\mathbb{N}$ & $+$ & $\times$ & $0$ &
            $1$ & $1$ & $1$ \\ \hline
            $\mathrm{WMC}$ & $\mathbb{R}_{\geq 0}$ & $+$ & $\times$
            & $0$ & $1$ & $\in \mathbb{R}^+$ & $\in \mathbb{R}^+$
            \\ \hline
            $\mathrm{PI}$ & $\mathbb{R}_{\geq 0}$ & $+$ & $\times$ &
            $0$ & $1$ & $\in [0,1]$ & $1-\alpha(v)$ \\ \hline
        \end{tabular}
    \end{center}
    \caption{Examples of logical and probabilistic inference
    tasks that can be modelled as AMC instances, together with
    their semirings and labelling functions.}
    \label{tab:amc}
\end{table}

\begin{center}

\end{center}

The semirings associated with SAT and probabilistic inference are often called
the \textit{Boolean} and the \textit{probability} semirings, respectively.

Other useful problems that can be modeled by the AMC task
are: \textit{sensitivity analysis} (SENS), \textit{probability
of most likely states} (MPE), \textit{shortest} and
\textit{widest path} (S-PATH and W-PATH, respectively),
\textit{fuzzy} and \textit{k-weighted} constraints (FUZZY and
k-WEIGHT, respectively), and $OBDD_<$ \textit{construction}
\citep{kimmig2017algebraic}.

\section{Second Level of Algebraic Model Counting}

As mathematicians are prone to do, there is a generalisation of
AMC, called 2AMC, which is capable of modeling
problems where there is the need of a third operation, besides
$\oplus$ and $\otimes$. This third operation appears in many
applications, such as the Maximum a Posteriori (MAP) probabilistic query, but is
also essential when modeling PASP problems, as we will see
in more detail in the next chapter \ref{ch:asp}.

Similarly to the AMC, follows the definition of the
2AMC problem \citep{kiesel2022efficient}:

\begin{definition}[Second-Level Algebraic Model Counting]
    Given
    \begin{itemize}
        \item A propositional logic theory $T$ over a set of
        variables $\mathcal{V}$;
        \item A partition of the variables in $T$,
        $(\mathbb{X}_I, \mathbb{X}_O)$;
        \item Two commutative semiring $S_j = (\mathcal{A}_j,
        \oplus_j, \otimes_j, e_{\oplus_j}, e_{\otimes_j})$, for
        $j \in \{I, O\}$;
        \item Two labelling functions $\alpha_j: X_j \rightarrow
        \mathcal{A}_j$, for $j \in \{I, O\}$, mapping literals
        of the variables in $X_j$ to elements of the semiring
        set $\mathcal{A}_j$; and
        \item A weight transformation function $t:
        \mathcal{A}_I \rightarrow \mathcal{A}_O$ that respects
        $t(e_{\oplus_I}) = e_{\oplus_O}$.
    \end{itemize}
    Then the 2AMC problem is defined as the computation of
    the following expression:
    \begin{displaymath}
        2AMC(T) = \bigoplus_{\mathbf{a} \in A(X_O)}^O
                  \bigotimes_{a \in \mathbf{a}}^O \alpha_O(a)
                  \otimes_O t
                  \left (
                  \bigoplus_{I \in \mathcal{M}(T|\mathbf{a})}^I
                  \bigotimes_{i \in I}^I \alpha_I(i) \right ),
    \end{displaymath}
    where $A(X)$ denotes the set of assignments of $x$ to $X \in
    \mathcal{V}$, and $\mathcal{M}(T|a)$ denotes the set of
    models of $T$ given an assignment $a$.
\end{definition}

It is easy to see that AMC is a special case of 2AMC. By choosing an empty
outer partition ($X_O = \emptyset$) and letting the weight transformation be the
identity, the outer summation collapses and we recover the original AMC
expression. Intuitively, 2AMC first enumerates assignments to the \emph{outer}
variables and re-weights the result of an \emph{inner} AMC computation on the
remaining variables before aggregating the outcomes.

A canonical example is Maximum a Posteriori (MAP) inference in probabilistic
models. Let $T$ be a propositional theory over variables $\mathcal{V}$,
partition its atoms into queries $Q$, evidence $E$, and the remaining hidden
variables $R$. Given evidence $e$, MAP seeks the most likely assignment to $Q$:
\[
    \mathrm{MAP}(Q \mid e) = \argmax_{q} \sum_{\mathbf{r} \in \mathcal{A}(R)}
    P(Q = q, E = e, R = \mathbf{r}),
\]
where $\mathcal{A}(R)$ enumerates assignments to $R$. Within 2AMC we set
$X_O = Q$ and $X_I = R \cup E$. The inner AMC sums over the hidden variables
for a fixed choice of $q$ and $e$, while the outer semiring combines these
values with a maximisation operator that selects the best query assignment.
The weight transformation $t$ merely injects the inner probability mass into
the outer semiring so that maximisation can be performed.

To complete the specification we instantiate the two semirings and the weight
transformation. The inner semiring is the standard probability semiring
$S_I = ([0,1], +, \times, 0, 1)$ with a labelling function $\alpha_I$ that
assigns unit weight to evidence literals consistent with $e$ and uses the
distributional parameters of $T$ for the remaining atoms. Inconsistent literals
receive weight $0$, ensuring that only models compatible with the evidence
contribute to the sum.

The outer semiring performs maximisation. We use
$S_O = (\mathbb{R}_{\ge 0} \times 2^{|Q|},
\oplus_{\mathrm{argmax}}, \otimes_{\mathrm{argmax}}, (0,\emptyset),
(1,\emptyset))$, where
\[
    (p_1, q_1) \oplus_{\mathrm{argmax}} (p_2, q_2) =
    \begin{cases}
        (p_1, q_1) & \text{if } p_1 > p_2, \\
        (p_2, q_2) & \text{if } p_2 > p_1, \\
        (p_1, \min\{q_1, q_2\}) & \text{otherwise},
    \end{cases}
\]
breaking ties by a fixed lexicographic order on assignments, and
$(p_1, q_1) \otimes_{\mathrm{argmax}} (p_2, q_2) = (p_1 \cdot p_2, q_1 \cup
q_2)$. The labelling $\alpha_O$ associates each literal with its local
probability and the singleton set containing that literal. Finally, the weight
transformation $t(p) = (p, \emptyset)$ carries the inner probability mass into
the outer semiring so that the maximisation can compare different assignments.
With these choices, 2AMC reproduces MAP inference exactly.

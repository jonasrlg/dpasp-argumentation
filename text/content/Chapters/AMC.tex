% Appendix Algebraic Model Counting

\chapter{Probabilistic Logical Inference} % Chapter title

\label{ch:amc} % For referencing the chapter elsewhere, use \autoref{ch:examples}
%----------------------------------------------------------------------------------------

The SAT problem can be coined as the cornerstone of
almost all research relating intractable problems in Computer
Science. Its pure logical nature arises many problems related
to Combinatorial or decision problems \citep{Cook_1971,
levin1973universal}. While SAT itself is a decision
problem, its optimization counterpart, the Max-SAT
problem, is also of great importance in many fields, from
Artificial Intelligence to Operations Research \citep{kolokolov2013analysis, gomes2006power}
and many other fields. On the other hand, the Sharp-SAT problem elevates
the combinatorial nature of SAT to a counting problem,
which increases its complexity and allows it as a reduction to
model many other counting problems \citep{valiant1979189}.

Another relevant generalization of SAT is the WMC, a
probabilistic generalization of Sharp-SAT, where each
assignment of the variables in the propositional logic theory
has an associated weight, and the problem is to compute the
sum of weights of all satisfying assignments.

The great importance of WMC, defined in Chapter
\ref{ch:sat}, is due to the fact that it provides a framework for performing probabilistic
inference. This result stems from the possibility of reducing
probabilistic inference calls to WMC on a propositional
knowledge base \cite{chavira2008probabilistic}. Specifically,
this approach derives from the possibility of encoding the
target probabilistic model, usually represented as a Bayesian Network,
into a set of propositional clauses, where each clause is a
knowledge base in CNF, and then assign weights to the
CNF variables based on the network probabilities
\citep{darwiche2002logical,chavira2006compiling,
chavira2008probabilistic,sang2005performing, costa2012clp}.

This possibility of reducing general probabilistic inference
queries on Bayesian Networks to WMC not only provides a declarative
method for encoding local structure (specific properties of
network parameters) and a powerful way for exploiting available
evidence \citep{chavira2008probabilistic}, but also enables the
use of highly optimized SAT solvers or Knowledge Compilation techniques
\citep{kimmig2017algebraic, chavira2008probabilistic}, which
renders some of today's most efficient techniques for
probabilistic inference \citep{kimmig2017algebraic}.

Given the importance of all problems described above, a unified
framework capable of modeling all of them was proposed, called
Algebraic Model Counting (AMC) \citep{kimmig2017algebraic}. Moreover, a second level
of this framework, naturally called Second-Level Algebraic Model Counting (2AMC), was proposed
recently \citep{kiesel2022efficient}, which is capable of
reducing inference in PASP.

%------------------------------------------------

\section{Algebraic Model Counting}

Before defining the AMC problem, we need to define the
type algebraic structure that is used to generalize tasks
such as SAT, Sharp-SAT and WMC. More
specifically, by generalizing these SAT-like problems
to a more abstract WMC over a different algebraic
structure, a \textit{comutative semiring}, we can define the
AMC problem as follows \citep{kimmig2017algebraic}:

\section{Semirings}

\begin{definition}[Semiring]
    A semiring is an algebraic structure $(\mathcal{A}, \oplus,
    \otimes, e_{\oplus}, e_{\otimes})$, where addition $\oplus$
    and multiplication $\otimes$ are associative binary
    operations over the set $\mathcal{A}$, $\oplus$ is
    commutative, $\otimes$ distributes over $\oplus$,
    $e_{\oplus} \in \mathcal{A}$ is the neutral element of (the
    sum operator) $\oplus$, $e_{\otimes} \in \mathcal{A}$ is the
    neutral element of (the product operator) $\otimes$, and for
    all $a \in \mathcal{A}$, $e_{\oplus} \otimes a = a \otimes
    e_{\oplus} = e_{\oplus}$. In a commutative semiring,
    $\otimes$ is commutative as well.
\end{definition}

One particular notable semiring is the \textit{Tropical
Semiring}, in the context of \textit{idempotent analysis}, where
the sum operator $\oplus$ is defined as the minimum operator,
and the product $\otimes$ operator is defined as the usual real
sum. The set $\mathcal{A}$ in this case is the set of extended
real numbers, $\Set{\mathbb{R} \cup \Set{+\infty}}$. This
important semiring has various applications, with a special
focus in \textit{Tropical Analysis} and \textit{Tropical
Geometry}, and is named after Imre Simon's extensive work on
this specific semiring \citep{simon1988recognizable}. Within the
context of AMC, the \textit{Tropical Semiring} can be used
to perform the Max-SAT problem, where the sum operator is
responsible for counting the number of satisfied clauses, and
the maximum operator is responsible for finding the maximum
number of satisfied clauses.

\section{Algebraic Model Counting}

\begin{definition}[Algebraic Model Counting]
    Given
    \begin{itemize}
        \item A propositional logic theory $T$ over a set of
        variables $\mathcal{V}$;
        \item A commutative semiring $(\mathcal{A}, \oplus,
        \otimes, e_{\oplus}, e_{\otimes})$; and
    \item A labeling function $\alpha: \mathcal{L}
        \rightarrow \mathcal{A}$, mapping literals $\mathcal{L}$
        of the variables in $\mathcal{V}$ to elements of the
        semiring set $\mathcal{A}$.
    \end{itemize}
    The AMC problem is now defined as the computation of
    the following expression:
    \begin{displaymath}
        A(T) = \bigoplus_{I \in \mathcal{M}(T)} \bigotimes_{i
        \in I} \alpha(i),
    \end{displaymath}
    where $\mathcal{M}(T)$ denotes the set of models of $T$.
\end{definition}

To anyone familiar with introductory algebra, it is easy to see
that the definition above for the AMC problem indeed
reduces many of the presented SAT like problems. For
example, by setting the semiring to
$$ (\mathcal{A}, \oplus, \otimes, e_{\oplus}, e_{\otimes}) =
(\{\mathit{true}, \mathit{false}\}, \lor, \land, \mathit{false},
\mathit{true}),$$

and $\alpha$ maps positive literals to \textit{true} and negative
literals to \textit{false}, we can see that the AMC problem
is capable of solving the SAT problem. Moreover, by setting
a similar semiring

$$ (\mathcal{A}, \oplus, \otimes, e_{\oplus}, e_{\otimes}) =
(\mathbb{N}, +, \times, 0, 1),$$

and $\alpha$ to map literals to $1$ and $0$, if they
are positive or negative, respectively, we can see that the
AMC models model counting.

Similarly, by only changing the set $\mathcal{A}$ of the
semiring to $\mathbb{R}^+$ (non-negative real numbers) and
$\alpha$ to also map literals to $\mathbb{R}^+$, we can see that
the AMC problem is capable of solving the WMC problem.

Moreover, by the results cited previously about Bayesian Networks, one can see
that this also means that AMC is also capable of reducing
general probabilistic inference \citep{darwiche2002logical,chavira2006compiling,
chavira2008probabilistic,sang2005performing}. However, the
algebraic structure of AMC makes it easy to show that it is
capable of modeling probabilistic inference: by using the same semiring used to
model the WMC problem and just by changing the $\alpha$
function to represent a probability distribution over the
literals, setting $a(v) \in [0,1]$ and $a(\overline{v})$ to be
its complement.

In fact, AMC is capable of modeling many other interesting
problems, such as $EXPEC$ (expectation), which allows one to
infer parameters in a Finite State Transducer model w.r.t. to a given dataset.
Hence, the elements of the respective expectation semiring are
tuples of the form $(p, v)$, where $p \in [0,1]$ is a
probability of an arc of the Finite State Transducer and $v \in \mathbb{R}$ is
the value of this respective arc. Then, the operations $\oplus,
\otimes$, neutral elements $e_{\oplus}, e_{\otimes}$, and the
labeling function $\alpha$ are defined as follows:

\begin{align*}
    (p_1, v_1) \oplus (p_2, v_2) & = (p_1 + p_2, v_1 + v_2), \\
    (p_1, v_1) \otimes (p_2, v_2) & = (p_1 \cdot p_2, p_1 \cdot
    v_2 + p_2 \cdot v_1), \\
    e_{\oplus} & = (0, 0), \\
    e_{\otimes} & = (1, 0), \\
    \alpha(a) & =
    \begin{cases}
        (p, 1) & \text{if } i = k, \\
        (p, 0) & \text{else.}
    \end{cases},
\end{align*}

where $a$ is the respective arc of the Finite State Transducer, in relation to
the tuple $(p, v)$.

%Furthermore, the AMC problem also is capable of reducing
%Max-SAT to it, by setting the semiring $(\mathbb{R}^+,
%\max, +, 0, 0)$, and the labeling function $\alpha(l)$, which
%maps literals to their respective weight contribution for all
%clause $c$ that the literal appears in. More specifically, the
%labeling function $\alpha$ is defined as follows:
%
%$$\alpha(l) = \sum_{c \in C : l \in c} \frac{w(c)}{|c|},$$
%
%where $C$ is the respective set of clauses of the propositional
%logic theory $T$, $w(c)$ is the weight of the clause $c$, and
%$|c|$ is the number of literals in the clause $c$.

Adapted from \citep{kimmig2017algebraic}, Table \ref{tab:amc}
summarizes the AMC problem for different logical and
probabilistic inference tasks, describind in depth the
respective sets, operations and labeling functions associated
with each semi-ring.

\begin{table}
    \begin{center}
        \begin{tabular}{|c||c|c|c|c|c|c|c|}
            \hline
            $\mathrm{Task}$ & $\mathcal{A}$ & $\oplus$ & $\otimes$ &
            $e^{\oplus}$ & $e^{\otimes}$ & $\alpha(v)$ &
            $\alpha(\neg v)$ \\ \hline \hline
            $\mathrm{SAT}$ & $\set{\mathit{true},\mathit{false}}$ &
            $\vee$ & $\wedge$ & $\mathit{false}$ & $\mathit{true}$ &
            $\mathit{true}$ & $\mathit{true}$ \\ \hline
            $\mathrm{\#SAT}$ & $\mathbb{N}$ & $+$ & $\times$ & $0$ &
            $1$ & $1$ & $1$ \\ \hline
            $\mathrm{WMC}$ & $\mathbb{R}_{\geq 0}$ & $+$ & $\times$
            & $0$ & $1$ & $\in \mathbb{R}^+$ & $\in \mathbb{R}^+$
            \\ \hline
            $\mathrm{PI}$ & $\mathbb{R}_{\geq 0}$ & $+$ & $\times$ &
            $0$ & $1$ & $\in [0,1]$ & $1-\alpha(v)$ \\ \hline
        \end{tabular}
    \end{center}
    \caption{Examples of logical and probabilistic inference
    tasks that can be modeled as instances of the AMC, and
    their corresponding semirings and labeling functions.}
    \label{tab:amc}
\end{table}

\begin{center}

\end{center}

Due to the importance of the semiring associated with SAT
and probabilistic inference, we give a special name to them: the
\textit{Boolean} and the \textit{Probability} semi-rings.

Other useful problems that can be modeled by the AMC task
are: \textit{sensitivity analysis} (SENS), \textit{probability
of most likely states} (MPE), \textit{shortest} and
\textit{widest path} (S-PATH and W-PATH, respectively),
\textit{fuzzy} and \textit{k-weighted} constraints (FUZZY and
k-WEIGHT, respetively), and $OBDD_<$ \textit{construction}
\citep{kimmig2017algebraic}.

\section{Second Level of Algebraic Model Counting}

As mathematical are prone to do, there is a generalization of
AMC, called 2AMC, which is capable of modeling
problems where there is the need of a third operation, besides
$\oplus$ and $\otimes$. This third operation appears in many
applications, such as the Maximum a Posteriori (MAP) probabilistical query, but is
also essential when modeling PASP problems, as we will see
in more detail in the next chapter \ref{ch:asp}.

Similarly to the AMC, follows the definition of the
2AMC problem \citep{kiesel2022efficient}:

\begin{definition}[Second-Level Algebraic Model Counting]
    Given
    \begin{itemize}
        \item A propositional logic theory $T$ over a set of
        variables $\mathcal{V}$;
        \item A partition of the variables in $T$,
        $(\mathbb{X}_I, \mathbb{X}_O)$;
        \item Two commutative semiring $S_j = (\mathcal{A}_j,
        \oplus_j, \otimes_j, e_{\oplus_j}, e_{\otimes_j})$, for
        $j \in \{I, O\}$;
        \item Two labeling function $\alpha_j: X_j \rightarrow
        \mathcal{A}_j$, for $j \in \{I, O\}$, mapping literals
        of the variables in $X_j$ to elements of the semiring
        set $\mathcal{A}_j$; and
        \item A weight transformation function $t:
        \mathcal{A}_I \rightarrow \mathcal{A}_O$ that respects
        $t(e_{\oplus_I}) = e_{\oplus_O}$.
    \end{itemize}
    Then the 2AMC problem is defined as the computation of
    the following expression:
    \begin{displaymath}
        2AMC(T) = \bigoplus_{\mathbf{a} \in A(X_O)}^O
                  \bigotimes_{a \in \mathbf{a}}^O \alpha_O(a)
                  \otimes_O t
                  \left (
                  \bigoplus_{I \in \mathcal{M}(T|\mathbf{a})}^I
                  \bigotimes_{i \in I}^I \alpha_I(i) \right ),
    \end{displaymath}
    where $A(X)$ denotes the set of assignments of $x$ to $X \in
    \mathcal{V}$, and $\mathcal{M}(T|a)$ denotes the set of
    models of $T$ given an assignment $a$.
\end{definition}

It is easy to see that AMC is an instance 2AMC, where
the first partition is empty, $X_O = \emptyset$, and the weight
transformation is the identity function. Thus, the leftmost half
of the equation (all elements outside the parentheses) is equal
applying the identity function, and the rightmost half is
equivalent to the AMC, because the assignment $\mathbf{a}$
inside the summation is empty, therefore, $M(T|\mathbf{a}) =
M(T)$. This implies that 2AMC tries to solve an instance of
AMC over the variables present in the partition $X_I$ for
each possible assignment of the variables in $X_O$, applying a
weight transformation to the result. From the algebraic point of
view, this weight transformation function maps the result of the
AMC inside the parentheses to the semiring $S_j$, used on
the left side of the equation. Thus, this transformation enables
one to solve a second AMC instance over the variables in
$X_O$.

Therefore, analyzing the 2AMC problem, we can see that it
partitions variables in $\mathcal{V}$ into two sets, $X_I$ and
$X_O$, and  then solves an inner AMC instance over the
variables presents in $X_I$ for each assignment to $X_O$. Then,
uses the results of this inner AMC instance to solve a
second (level) AMC instance over the variables in $X_O$.

Perhaps, a non-trivial example of a problem that can be modeled
as an instance of 2AMC is the MAP query, which is
defined to be the most probable assignment $q$ given an
evidence $e$ (the assignment of the remaining variables that is
more likely given the evidence). Formally, given a propositional
logic theory $T$ over variables $\mathcal{V}$, a joint
probability distribution $P$ over $T$, a conjunction $e$ of
observed literals for the set of evidence atoms $E$, and a set
of ground query atoms $Q$: find the most probable assignment $q$ to $Q$
given the evidence $e$, with $R = \mathcal{V} \setminus (Q \cup
E)$

$$MAP(Q|e) = \argmax_q P(Q = q|e) = \argmax_q \sum_{\mathbf{r}
\in \mathcal{A}(R)} P(Q = q, e, R = r),$$

where $\mathcal{A}(R)$ denotes the set of assignments of $r$
to $R$.

Under the assumption that the distribution the Random Variables
respective to the variables in $Q$ are independent (the
distribution is factorized w.r.t. $Q$), we can see that MAP
query consists of two steps:

\begin{enumerate}
    \item A first AMC task of solving the sum over the
    truth values of the atoms in $R$, when considering fixed
    assignments to the atoms both in $E$ and $Q$; and
    \item A second AMC task of determining the assignments
    to the variables in $Q$ that maximize the inner sum of the
    first AMC task.
\end{enumerate}

This intuitive description of the MAP query illustrates how
it could be modeled as an instance of the 2AMC problem. By
having the partitions of variables to be $X_O = Q$ and $X_I =
\mathcal{V} \setminus Q = R \cup E$, we have a compatible
partition of the variables in $\mathcal{V}$ w.r.t. the MAP
problem.

With the partition of variables defined, there is still the need
to define the semirings, labeling functions, and the weight
transformation function $t$. Since the rightmost half of the
equation is w.r.t. to summing the probabilities over assignments
$r$ to $R$, the semiring used for this part of the equation is
$S_I = ([0, 1], +, \times, 0, 1)$ (the same semiring used for
probabilistic inference); and the labeling function $\alpha_I$ maps literals
present in $e$ to $1$ and $0$ to their negation, $P(r)$ and
$1 - P(r)$ to the positive and negative literals present in $R$
(thus, the probability of assignments that are not "compatible"
with $e$ is zero).

On the other hand, the leftmost half of the equation represents
a maximization of the truth values of the atoms in $Q$, given
the result of the inner AMC instance. Therefore, the
semiring used for this part of the equation is $S_O = (R^+
\times 2^{|Q|}, \oplus_{\mathrm{argmax}},
\otimes_{\mathrm{argmax}}, (0, \emptyset), (1, \emptyset))$,
where

$$(p_1, q_1) \oplus_{\mathrm{argmax}} (p_2, q_2) =
\begin{cases}
    (p_1, q_1) & p_1 > p_2 \\
    (p_2, q_2) & p_1 < p_2 \\
    (p_1, q_{\mathrm{min}}) & p_1 = p_2
\end{cases}
$$

and $q_{\mathrm{min}}$ represents the smallest assigment of
literals, w.r.t. a predefinied lexycographic order of the
variables $Q$; and $\otimes_{\mathrm{argmax}}$ is defined as the
product between the probabilities of the assignments, and the
union of the assignments of the literals, $(p_1, q_1)
\otimes_{\mathrm{argmax}} (p_2, q_2) = (p_1 \cdot p_2, q_1 \cup
q_2)$. Moreover, to complete the definition of the this
leftmost AMC instance, the labeling function $\alpha_O(l)$
is defined to be: $(p, \{l\})$ for the positive literals; and
$(1 - p, \{l\})$ for the negative ones.

Finally, to completely describe MAP as an instance of the
2AMC problem, we construct the function $t(p)$, where $p$
is the resulting probability of the inner (rightmost) AMC
task, as being $t(p) = (p, \emptyset)$. This weight
transformation function takes the sum of the probabilities as
input and just returns the Cartesian Product of the
probability and the empty set, which is the neutral element of
the $\oplus_{\mathrm{argmax}}$ operator. Next, the $\otimes_{
\mathrm{argmax}}$ will take the product of the probabilities an
assignment of a variable in $Q$ and the result probability of
the inner AMC. In other words, the probability $P(q)$,
where $q \in \mathbf{q}$ and $\mathbf{q}$ is the assignment of
the variables in $Q$, is multiplied by the sum of probabilities
conditioned on the assignment $q$ and evidence $e$. The second
part of the tuple is the union between $q$ and $\emptyset$,
which is equal to $q$. Thus, the $\otimes_{\mathrm{argmax}}$
applies the Bayes Rule to the result of the inner AMC,
multiplying the probability of the assignment of the variables.
Therefore, the last step, $\oplus_{\mathrm{argmax}}$, takes the
assignment that maximizes the probability of the computation
performed by the $\otimes_{\mathrm{argmax}}$ operator, which
results in the most probable assignment of the variables in $Q$.

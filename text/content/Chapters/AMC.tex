% Appendix Algebraic Model Counting

\chapter{Probabilistic Logical Inference} % Chapter title

\label{ch:amc} % For referencing the chapter elsewhere, use \autoref{ch:examples}
%----------------------------------------------------------------------------------------

Chapter \autoref{ch:sat} introduced SAT and its counting and optimisation
variants. Weighted model counting (WMC) is especially important for us because
it reduces many probabilistic inference tasks to summing weights over satisfying
assignments \citep{darwiche2002logical,chavira2008probabilistic}. By encoding,
for example, a Bayesian network as a propositional theory whose literals carry
probabilities, WMC answers marginal queries through purely logical machinery.

Knowledge compilation builds on this reduction: once a theory has been compiled
into a circuit that supports fast WMC, evidence and query evaluation become
linear in the circuit size \citep{chavira2006compiling,kimmig2017algebraic}. To
reason about PASP we need a framework that encompasses classical SAT, WMC, and
other algebraic tasks. Algebraic Model Counting (AMC) provides precisely that
unifying perspective \citep{kimmig2017algebraic}. A recent extension, second
level AMC (2AMC), further captures probabilistic ASP inference
\citep{kiesel2022efficient}. This chapter introduces these abstractions and
prepares the ground for the compilation pipeline described later.

%------------------------------------------------

\section{From SAT to AMC}

Before defining AMC we recall the algebraic structure that underpins it.
Generalising from simple numeric addition and multiplication allows us to model
counting, optimisation, and probability computations within the same template.

\section{Semirings}

\begin{definition}[Semiring]
    A semiring is an algebraic structure $(\mathcal{A}, \oplus,
    \otimes, e_{\oplus}, e_{\otimes})$ where addition $\oplus$
    and multiplication $\otimes$ are associative binary
    operations on $\mathcal{A}$, $\oplus$ is commutative,
    $\otimes$ distributes over $\oplus$, $e_{\oplus}$ and
    $e_{\otimes}$ are neutral elements for $\oplus$ and $\otimes$,
    respectively, and $e_{\oplus}$ annihilates multiplication:
    $e_{\oplus} \otimes a = a \otimes e_{\oplus} = e_{\oplus}$
    for every $a \in \mathcal{A}$. In a \emph{commutative}
    semiring, multiplication $\otimes$ is also commutative.
\end{definition}

Semirings appear throughout computer science. The \emph{tropical} semiring, for
instance, replaces addition with the minimum operator and multiplication with
the standard addition over extended real numbers
\citep{simon1988recognizable}. When used with AMC it captures optimisation tasks
like Max-SAT: summations aggregate clause scores while products accumulate costs
along a derivation.

\section{Algebraic Model Counting}

\begin{definition}[Algebraic Model Counting]
    Given
    \begin{itemize}
        \item A propositional logic theory $T$ over a set of
        variables $\mathcal{V}$;
        \item A commutative semiring $(\mathcal{A}, \oplus,
        \otimes, e_{\oplus}, e_{\otimes})$; and
        \item A labelling function $\alpha: \mathcal{L}
        \rightarrow \mathcal{A}$, mapping literals $\mathcal{L}$
        of the variables in $\mathcal{V}$ to elements of the
        semiring set $\mathcal{A}$.
    \end{itemize}
    The AMC problem is now defined as the computation of
    the following expression:
    \begin{displaymath}
        A(T) = \bigoplus_{I \in \mathcal{M}(T)} \bigotimes_{i
        \in I} \alpha(i),
    \end{displaymath}
    where $\mathcal{M}(T)$ denotes the set of models of $T$.
\end{definition}

To anyone familiar with introductory algebra, it is easy to see
that the construction above subsumes many SAT-like problems. For
example, by setting the semiring to
$$ (\mathcal{A}, \oplus, \otimes, e_{\oplus}, e_{\otimes}) =
(\{\mathit{true}, \mathit{false}\}, \lor, \land, \mathit{false},
\mathit{true}),$$

and mapping every literal to $\mathit{true}$ through $\alpha$, the AMC
expression collapses to Boolean reasoning and therefore decides SAT. Moreover,
by choosing

$$ (\mathcal{A}, \oplus, \otimes, e_{\oplus}, e_{\otimes}) =
(\mathbb{N}, +, \times, 0, 1),$$

and mapping both positive and negative literals to $1$, the resulting AMC
computation counts how many models satisfy the theory.

Similarly, by only changing the set $\mathcal{A}$ of the
semiring to $\mathbb{R}_{\ge 0}$ (non-negative real numbers) and
letting $\alpha$ assign literal weights in $\mathbb{R}_{\ge 0}$, the AMC
problem recovers weighted model counting.

Moreover, the results cited previously about Bayesian networks imply that AMC
also captures probabilistic inference
\citep{darwiche2002logical,chavira2006compiling,
chavira2008probabilistic,sang2005performing}. The algebraic structure makes the
connection explicit: using the same semiring and defining
$\alpha(v) \in [0,1]$ as the probability of literal $v$, with
$\alpha(\neg v) = 1 - \alpha(v)$ for binary variables, yields the desired
probability mass assignments.

\begin{example}
    Consider the theory $T = (a \lor b)$ and the probability
    semiring $\big(\mathbb{R}_{\geq 0}, +, \times, 0, 1\big)$.
    Let the labelling function assign weights
    $\alpha(a)=0.6$, $\alpha(\neg a)=0.4$, $\alpha(b)=0.3$, and
    $\alpha(\neg b)=0.7$. The models that satisfy $T$ are all
    assignments except $(\neg a, \neg b)$. Applying the AMC
    formula yields
    \[
        A(T) = 1 - \alpha(\neg a)\alpha(\neg b)
             = 1 - 0.4 \times 0.7 = 1 - 0.28 = 0.72,
    \]
    which coincides with the probability that at least one of
    $a$ or $b$ is true. This simple computation mirrors the WMC
    task we will perform on compiled circuits.
\end{example}

In fact, AMC is capable of modeling many other interesting
problems, such as $EXPEC$ (expectation), which allows one to
infer parameters in a finite-state transducer relative to a given dataset.
The elements of the respective expectation semiring are
tuples of the form $(p, v)$, where $p \in [0,1]$ is the
probability of traversing a particular arc and $v \in \mathbb{R}$ is
the value contributed by that arc. The operations $\oplus,
\otimes$, neutral elements $e_{\oplus}, e_{\otimes}$, and a suitable
labelling function are defined as follows:

\begin{align*}
    (p_1, v_1) \oplus (p_2, v_2) & = (p_1 + p_2, v_1 + v_2), \\
    (p_1, v_1) \otimes (p_2, v_2) & = (p_1 \cdot p_2, p_1 \cdot
    v_2 + p_2 \cdot v_1), \\
    e_{\oplus} & = (0, 0), \\
    e_{\otimes} & = (1, 0), \\
    \alpha(a) & = (p_a, p_a \cdot v_a),
\end{align*}

where each arc $a$ carries probability $p_a$ and reward $v_a$.

%Furthermore, the AMC problem also is capable of reducing
%Max-SAT to it, by setting the semiring $(\mathbb{R}^+,
%\max, +, 0, 0)$, and the labeling function $\alpha(l)$, which
%maps literals to their respective weight contribution for all
%clause $c$ that the literal appears in. More specifically, the
%labeling function $\alpha$ is defined as follows:
%
%$$\alpha(l) = \sum_{c \in C : l \in c} \frac{w(c)}{|c|},$$
%
%where $C$ is the respective set of clauses of the propositional
%logic theory $T$, $w(c)$ is the weight of the clause $c$, and
%$|c|$ is the number of literals in the clause $c$.

Adapted from \citep{kimmig2017algebraic}, Table \ref{tab:amc}
summarises AMC instances for different logical and probabilistic
tasks, detailing the underlying sets, operations, and labelling
functions for each semiring.

\begin{table}
    \begin{center}
        \begin{tabular}{|c||c|c|c|c|c|c|c|}
            \hline
            $\mathrm{Task}$ & $\mathcal{A}$ & $\oplus$ & $\otimes$ &
            $e^{\oplus}$ & $e^{\otimes}$ & $\alpha(v)$ &
            $\alpha(\neg v)$ \\ \hline \hline
            $\mathrm{SAT}$ & $\set{\mathit{true},\mathit{false}}$ &
            $\vee$ & $\wedge$ & $\mathit{false}$ & $\mathit{true}$ &
            $\mathit{true}$ & $\mathit{true}$ \\ \hline
            $\mathrm{\#SAT}$ & $\mathbb{N}$ & $+$ & $\times$ & $0$ &
            $1$ & $1$ & $1$ \\ \hline
            $\mathrm{WMC}$ & $\mathbb{R}_{\geq 0}$ & $+$ & $\times$
            & $0$ & $1$ & $\in \mathbb{R}^+$ & $\in \mathbb{R}^+$
            \\ \hline
            $\mathrm{PI}$ & $\mathbb{R}_{\geq 0}$ & $+$ & $\times$ &
            $0$ & $1$ & $\in [0,1]$ & $1-\alpha(v)$ \\ \hline
        \end{tabular}
    \end{center}
    \caption{Examples of logical and probabilistic inference
    tasks that can be modelled as AMC instances, together with
    their semirings and labelling functions.}
    \label{tab:amc}
\end{table}

The semirings associated with SAT and probabilistic inference are often called
the \textit{Boolean} and the \textit{probability} semirings, respectively.

Other useful problems that can be modeled by the AMC task
are: \textit{sensitivity analysis} (SENS), \textit{probability
of most likely states} (MPE), \textit{shortest} and
\textit{widest path} (S-PATH and W-PATH, respectively),
\textit{fuzzy} and \textit{k-weighted} constraints (FUZZY and
k-WEIGHT, respectively), and $OBDD_<$ \textit{construction}
\citep{kimmig2017algebraic}.

\section{Second Level of Algebraic Model Counting}

A natural generalisation of AMC introduces a third operation alongside
$\oplus$ and $\otimes$. The resulting framework, called 2AMC, captures tasks
such as Maximum a Posteriori (MAP) inference and is essential when modelling
PASP problems, as we will see in Chapter~\ref{ch:asp}.

We now recall the definition of the 2AMC problem
\citep{kiesel2022efficient}:

\begin{definition}[Second-Level Algebraic Model Counting]
    Given
    \begin{itemize}
        \item A propositional logic theory $T$ over a set of
        variables $\mathcal{V}$;
        \item A partition of the variables in $T$,
        $(X_I, X_O)$;
        \item Two commutative semirings $S_j = (\mathcal{A}_j,
        \oplus_j, \otimes_j, e_{\oplus_j}, e_{\otimes_j})$, for
        $j \in \{I, O\}$;
        \item Two labelling functions $\alpha_j: \mathcal{L}(X_j) \rightarrow
        \mathcal{A}_j$, for $j \in \{I, O\}$, mapping literals
        over the variables in $X_j$ to elements of the semiring
        set $\mathcal{A}_j$; and
        \item A weight transformation function $t:
        \mathcal{A}_I \rightarrow \mathcal{A}_O$ that respects
        $t(e_{\oplus_I}) = e_{\oplus_O}$.
    \end{itemize}
    Then the 2AMC problem is defined as the computation of
    the following expression:
    \begin{displaymath}
        2AMC(T) = \bigoplus_{\mathbf{a} \in \mathcal{A}(X_O)}^O
                  \bigotimes_{a \in \mathbf{a}}^O \alpha_O(a)
                  \otimes_O t
                  \left (
                  \bigoplus_{I \in \mathcal{M}(T|\mathbf{a})}^I
                  \bigotimes_{i \in I}^I \alpha_I(i) \right ),
    \end{displaymath}
    \noindent where $\mathcal{A}(X)$ denotes the set of assignments to the variables in
    $X$, and $\mathcal{M}(T|\mathbf{a})$ denotes the set of models of $T$
    consistent with assignment $\mathbf{a}$.
\end{definition}

It is easy to see that AMC is a special case of 2AMC. By choosing an empty
outer partition ($X_O = \emptyset$) and letting the weight transformation be the
identity, the outer summation collapses and we recover the original AMC
expression. Intuitively, 2AMC first enumerates assignments to the \emph{outer}
variables and re-weights the result of an \emph{inner} AMC computation on the
remaining variables before aggregating the outcomes.

A canonical example is Maximum a Posteriori (MAP) inference in probabilistic
models. Let $T$ be a propositional theory over variables $\mathcal{V}$,
partition its atoms into queries $Q$, evidence $E$, and the remaining hidden
variables $R$. Given evidence $e$, MAP seeks the most likely assignment to $Q$:
\[
    \mathrm{MAP}(Q \mid e) = \argmax_{q} \sum_{\mathbf{r} \in \mathcal{A}(R)}
    P(Q = q, E = e, R = \mathbf{r}),
\]
where $\mathcal{A}(R)$ enumerates assignments to $R$. Within 2AMC we set
$X_O = Q$ and $X_I = R \cup E$. The inner AMC sums over the hidden variables
for a fixed choice of $q$ and $e$, while the outer semiring combines these
values with a maximisation operator that selects the best query assignment.
The weight transformation $t$ merely injects the inner probability mass into
the outer semiring so that maximisation can be performed.

To complete the specification we instantiate the two semirings and the weight
transformation. The inner semiring is the standard probability semiring
$S_I = ([0,1], +, \times, 0, 1)$ with a labelling function $\alpha_I$ that
assigns unit weight to evidence literals consistent with $e$ and uses the
distributional parameters of $T$ for the remaining atoms. Inconsistent literals
receive weight $0$, ensuring that only models compatible with the evidence
contribute to the sum.

The outer semiring performs maximisation. We use
$S_O = (\mathbb{R}_{\ge 0} \times 2^{|Q|},
\oplus_{\mathrm{argmax}}, \otimes_{\mathrm{argmax}}, (0,\emptyset),
(1,\emptyset))$, where
\[
    (p_1, q_1) \oplus_{\mathrm{argmax}} (p_2, q_2) =
    \begin{cases}
        (p_1, q_1) & \text{if } p_1 > p_2, \\
        (p_2, q_2) & \text{if } p_2 > p_1, \\
        (p_1, \min\{q_1, q_2\}) & \text{otherwise},
    \end{cases}
\]
breaking ties by a fixed lexicographic order on assignments, and
$(p_1, q_1) \otimes_{\mathrm{argmax}} (p_2, q_2) = (p_1 \cdot p_2, q_1 \cup
q_2)$. The labelling $\alpha_O$ associates each literal with its local
probability and the singleton set containing that literal. Finally, the weight
transformation $t(p) = (p, \emptyset)$ carries the inner probability mass into
the outer semiring so that the maximisation can compare different assignments.
With these choices, 2AMC reproduces MAP inference exactly.
